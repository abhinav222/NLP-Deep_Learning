{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"tfidf-chatbot.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"QIJqhVhe7m8j","colab_type":"text"},"source":["# Different Types Of Chatbot\n","\n","There are broadly two variants of chatbots: Rule-Based and Self learning.\n","\n","In a Rule-based approach, a bot answers questions based on some rules on which it is trained on. The rules defined can be very simple to very complex. The bots can handle simple queries but fail to manage complex ones.\n","\n","The Self learning bots are the ones that use some Machine Learning-based approaches and are definitely more efficient than rule-based bots. These bots can be of further two types: Retrieval Based or Generative\n","\n","i) In retrieval-based models, a chatbot uses some heuristic to select a response from a library of predefined responses. The chatbot uses the message and context of conversation for selecting the best response from a predefined list of bot messages. The context can include a current position in the dialog tree, all previous messages in the conversation, previously saved variables (e.g. username). Heuristics for selecting a response can be engineered in many different ways, from rule-based if-else conditional logic to machine learning classifiers.\n","\n","ii) Generative bots can generate the answers and not always replies with one of the answers from a set of answers. This makes them more intelligent as they take word by word from the query and generates the answers.\n","\n","We are building a retrieval-based chatbot (Using TF-IDF approach)."]},{"cell_type":"code","metadata":{"id":"0FltuWhE7m8k","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593928273032,"user_tz":-330,"elapsed":1648,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["import nltk\n","import numpy as np\n","import random\n","import string "],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"iVZoejduInJR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1593928261764,"user_tz":-330,"elapsed":36100,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"05bc29e0-ee54-41e8-c725-cebd4c4c70a9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"emeNddFR7m8o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1593928277668,"user_tz":-330,"elapsed":2388,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"4f390f50-1228-4055-b1f2-208ccfcbb2e4"},"source":["f = open('/content/drive/My Drive/nlp/tfidf-chatbot-master/chatbot.txt', 'r', errors = 'ignore')\n","raw = f.read()\n","raw = raw.lower()\n","nltk.download('punkt') #tokenizer for english\n","nltk.download('wordnet') #corpora\n","sent_tokens = nltk.sent_tokenize(raw) #convert to list of sentences\n","word_tokens = nltk.word_tokenize(raw) #convert to list of words"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"saudq0YS7m8r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1593704033536,"user_tz":-330,"elapsed":915,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"546655fb-23e4-4dca-dc9b-8af7a3b9ea86"},"source":["sent_tokens[:2]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['a chatbot (also known as a smartbot, talkbot, chatterbot, bot, im bot, interactive agent, conversational interface or artificial conversational entity) is a computer program or an artificial intelligence which conducts a conversation via auditory or textual methods.',\n"," '[1] such programs are often designed to convincingly simulate how a human would behave as a conversational partner, thereby passing the turing test.']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"1a3raYK37m8y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593928312883,"user_tz":-330,"elapsed":877,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"494e5f1b-c649-45b3-d9a7-3cc21a1a384d"},"source":["word_tokens[:2]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['a', 'chatbot']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"3WGR4vuv7m82","colab_type":"text"},"source":["# Preprocessing the text"]},{"cell_type":"code","metadata":{"id":"2OmRdpPg7m82","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593928401034,"user_tz":-330,"elapsed":842,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["lemmer = nltk.stem.WordNetLemmatizer()\n","#Wordnet is a semantically-oriented dictionary of English included in NLTK\n","\n","def lemTokens(tokens):\n","    return [lemmer.lemmatize(token) for token in tokens]\n","\n","def lemNormalize(text):\n","    return lemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n","\n","remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W5a5PBAu7m84","colab_type":"text"},"source":["# Greeting by Keyword Matching"]},{"cell_type":"code","metadata":{"id":"rS5WA4Pc7m85","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593928754668,"user_tz":-330,"elapsed":1895,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\",)\n","\n","GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n","\n","def greeting(sentence):\n","    for word in sentence.split():\n","        if word.lower() in GREETING_INPUTS:\n","            return random.choice(GREETING_RESPONSES)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3H_V2qBI7m87","colab_type":"text"},"source":["# Generating response to a query using TF-IDF"]},{"cell_type":"code","metadata":{"id":"-P9-0-Ph7m88","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593928491558,"user_tz":-330,"elapsed":882,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"k68eHoxQ7m8_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593928602209,"user_tz":-330,"elapsed":860,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["def response(user_response):\n","    robo_response = ''\n","    sent_tokens.append(user_response)\n","    TfidfVec = TfidfVectorizer(tokenizer=lemNormalize, stop_words = 'english')\n","    \n","    # Get the TF IDF weighted Document-Term Matrix\n","    tfidf = TfidfVec.fit_transform(sent_tokens) \n","    # print(\"Document Count\", len(sent_tokens), \"Term Count\", len(TfidfVec.get_feature_names()))\n","    # print(TfidfVec.get_feature_names())\n","    \n","    # Get the cosine similarity between user query and all the sentences in corpora. This will be a vector of similarities\n","    vals = cosine_similarity(tfidf[-1], tfidf)\n","    \n","    # Get the sentence (document) which matches the most with the query\n","    idx = vals.argsort()[0][-2]\n","    \n","    # Get the td-idf value of the index which matched the most\n","    flat = vals.flatten()\n","    flat.sort()\n","    req_tfidf = flat[-2]\n","    \n","    if(req_tfidf == 0):\n","        robo_response =  \"I am sorry! I don't understand you\"\n","    else:\n","        robo_response = sent_tokens[idx]\n","        \n","    sent_tokens.remove(user_response)\n","    return robo_response\n","\n","# response(\"conference chatbot\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"tF7LMPDi7m9B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":181},"outputId":"f5c78ee9-6aa3-4933-f6c3-51dca5a24919"},"source":["flag = True\n","\n","print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye! \")\n","\n","while( flag == True):\n","    user_response = input()\n","    user_response = user_response.lower()\n","    \n","    if(user_response != 'bye'):\n","        if(user_response == 'thanks' or user_response == 'thank_you'):\n","            flag = False\n","            print(\"ROBO: You are welcome..\")\n","        else:\n","            if(greeting(user_response) != None):\n","                print(\"ROBO: \"+greeting(user_response))\n","            else:\n","                print(\"ROBO: \", end=\"\")\n","                print(response(user_response))\n","    else:\n","        flag = False\n","        print(\"ROBO: Bye! take care..\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye! \n","who invented chatbots\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n","  'stop_words.' % sorted(inconsistent))\n"],"name":"stderr"},{"output_type":"stream","text":["ROBO: [23][24]\n","\n","a 2017 study showed 4% of companies used chatbots.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aRfmPENa7m9E","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}