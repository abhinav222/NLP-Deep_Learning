{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5- How to use Spark NLP and Spark ML Pipelines.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"spark_nlp_2.4.4","language":"python","name":"spark_nlp_2.4.4"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BxzW_3bimNjP"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"epkk3MUMmNjR"},"source":["# Spark NLP and Spark ML Pipelines"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LwLEsf3LmPx5","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1595135680641,"user_tz":-330,"elapsed":16916,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"acd0c851-8a63-41af-afba-c9d1bbc4745f"},"source":["import os\n","\n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! java -version\n","\n","# Install pyspark\n","! pip install --ignore-installed pyspark==2.4.4\n","\n","# Install Spark NLP\n","! pip install --ignore-installed spark-nlp==2.5.1"],"execution_count":4,"outputs":[{"output_type":"stream","text":["openjdk version \"1.8.0_252\"\n","OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n","OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n","Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n","Collecting py4j==0.10.7\n","  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.7 pyspark-2.4.4\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["py4j","pyspark"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting spark-nlp==2.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/b4/db653f8080a446de8ce981b262d85c85c61de7e920930726da0d1c6b4c65/spark_nlp-2.5.1-py2.py3-none-any.whl (121kB)\n","\r\u001b[K     |██▊                             | 10kB 12.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 2.8MB/s \n","\u001b[?25hInstalling collected packages: spark-nlp\n","Successfully installed spark-nlp-2.5.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ouQjb9kWmNjS"},"source":["## Simple Topic Modeling\n","\n","`Spark-NLP`\n","* DocumentAssembler\n","* SentenceDetector\n","* Tokenizer\n","* Normalizer\n","* POS tagger\n","* Chunker\n","* Finisher\n","\n","`Spark ML`\n","* Hashing\n","* TF-IDF\n","* LDA"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8aKWnMGkmNjU","colab":{},"executionInfo":{"status":"ok","timestamp":1595135684773,"user_tz":-330,"elapsed":871,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["import sys\n","import time\n","\n","from pyspark.sql.functions import col\n","from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, Tokenizer\n","from pyspark.ml.clustering import LDA, LDAModel\n","\n","#Spark NLP\n","import sparknlp\n","from sparknlp.pretrained import PretrainedPipeline\n","from sparknlp.annotator import *\n","from sparknlp.common import RegexRule\n","from sparknlp.base import *"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q3wJ02KWmNjY"},"source":["### Let's create a Spark Session for our app"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"irMmrC0JmNjZ","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595135708647,"user_tz":-330,"elapsed":20285,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"c12151e3-9b47-4866-deef-f420cf76430b"},"source":["spark = sparknlp.start()\n","\n","print(\"Spark NLP version: \", sparknlp.version())\n","print(\"Apache Spark version: \", spark.version)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Spark NLP version:  2.5.1\n","Apache Spark version:  2.4.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"s8DvVMvnmNjd"},"source":["Let's download some scientific sample from PubMed dataset:\n","```\n","wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp\n","```"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ndXJqm2LmNje","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1595135713057,"user_tz":-330,"elapsed":2651,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"4521716c-d243-41f9-8d93-daf2d908bf35"},"source":["! wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp"],"execution_count":7,"outputs":[{"output_type":"stream","text":["--2020-07-19 05:15:52--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.114.37\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.114.37|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10484510 (10.0M) [text/csv]\n","Saving to: ‘/tmp/pubmed-sample.csv’\n","\n","\rpubmed-sample.csv     0%[                    ]       0  --.-KB/s               \rpubmed-sample.csv   100%[===================>]  10.00M  51.7MB/s    in 0.2s    \n","\n","2020-07-19 05:15:52 (51.7 MB/s) - ‘/tmp/pubmed-sample.csv’ saved [10484510/10484510]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bUeGQLVGmNjh","colab":{},"executionInfo":{"status":"ok","timestamp":1595135727768,"user_tz":-330,"elapsed":9833,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["pubMedDF = spark.read\\\n","                .option(\"header\", \"true\")\\\n","                .csv(\"/tmp/pubmed-sample.csv\")\\\n","                .filter(\"AB IS NOT null\")\\\n","                .withColumn(\"text\", col(\"AB\"))\\\n","                .drop(\"TI\", \"AB\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n9rmOCPrmNjk","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"ok","timestamp":1595135731426,"user_tz":-330,"elapsed":1300,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"cf2139bb-773e-4e29-adda-47ea0daadcab"},"source":["pubMedDF.printSchema()\n","pubMedDF.show()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["root\n"," |-- text: string (nullable = true)\n","\n","+--------------------+\n","|                text|\n","+--------------------+\n","|The human KCNJ9 (...|\n","|BACKGROUND: At pr...|\n","|OBJECTIVE: To inv...|\n","|Combined EEG/fMRI...|\n","|Kohlschutter synd...|\n","|Statistical analy...|\n","|The synthetic DOX...|\n","|Our objective was...|\n","|We conducted a ph...|\n","|\"Monomeric sarcos...|\n","|We presented the ...|\n","|The literature de...|\n","|A novel approach ...|\n","|An HPLC-ESI-MS-MS...|\n","|The localizing an...|\n","|OBJECTIVE: To eva...|\n","|For the construct...|\n","|We report the res...|\n","|Intraparenchymal ...|\n","|It is known that ...|\n","+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1P7fpHe0mNjm","scrolled":true,"colab":{},"executionInfo":{"status":"ok","timestamp":1595135747909,"user_tz":-330,"elapsed":2035,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["pubMedDF.count()\n","pubMedDF = pubMedDF.limit(2000) "],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8jGB30xSmNjp"},"source":["### Let's create Spark-NLP Pipeline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GcltBIMymNjq","colab":{"base_uri":"https://localhost:8080/","height":986},"executionInfo":{"status":"error","timestamp":1595135833688,"user_tz":-330,"elapsed":1168,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"ea52d1b8-42e0-4afe-8acb-01e262f2afcb"},"source":["# Spark NLP Pipeline\n","\n","document_assembler = DocumentAssembler() \\\n","    .setInputCol(\"text\")\n","\n","sentence_detector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","\n","posTagger = PerceptronModel.pretrained() \\\n","  .setInputCols([\"sentence\", \"token\"])\n","\n","chunker = Chunker() \\\n","    .setInputCols([\"sentence\", \"pos\"]) \\\n","    .setOutputCol(\"chunk\") \\\n","    .setRegexParsers([\"<NNP>+\", \"<DT>?<JJ>*<NN>\"])\n","\n","finisher = Finisher() \\\n","  .setInputCols([\"chunk\"]) \\\n","  .setIncludeMetadata(False)\n","\n","nlpPipeline = Pipeline(stages=[\n","    document_assembler, \n","    sentence_detector, \n","    tokenizer,\n","    posTagger,\n","    chunker,\n","    finisher\n","])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["pos_anc download started this may take some time.\n"],"name":"stdout"},{"output_type":"error","ename":"Py4JJavaError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-819fd8bb6949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetInputCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"token\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mposTagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0msetInputCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetInputCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetRegexParsers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<NNP>+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<DT>?<JJ>*<NN>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparknlp/annotator.py\u001b[0m in \u001b[0;36mpretrained\u001b[0;34m(name, lang, remote_loc)\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pos_anc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0msparknlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResourceDownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mResourceDownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPerceptronModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparknlp/pretrained.py\u001b[0m in \u001b[0;36mdownloadModel\u001b[0;34m(reader, name, language, remote_loc, j_dwn)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_dwn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PythonResourceDownloader'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" download started this may take some time.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mfile_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GetResourceSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"-1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not find the model to download please check the name!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, language, remote_loc)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         super(_GetResourceSize, self).__init__(\n\u001b[0;32m--> 192\u001b[0;31m             \"com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.getDownloadSize\", name, language, remote_loc)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, java_obj, *args)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExtendedJavaWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36mnew_java_obj\u001b[0;34m(self, java_class, *args)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_java_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpylist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n","\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.getDownloadSize.\n: com.amazonaws.services.s3.model.AmazonS3Exception: Forbidden (Service: Amazon S3; Status Code: 403; Error Code: 403 Forbidden; Request ID: 21AB809A8D8A5D46; S3 Extended Request ID: QnRs/GvWHrcFq2U7K+hhZuCvtz9ogUhcanpsw8ghSUjNzhtaqIocb+G4r6fj2OohtOE/iceaBrE=), S3 Extended Request ID: QnRs/GvWHrcFq2U7K+hhZuCvtz9ogUhcanpsw8ghSUjNzhtaqIocb+G4r6fj2OohtOE/iceaBrE=\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1712)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1367)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1113)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:770)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:744)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:726)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:686)\n\tat com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:668)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:532)\n\tat com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:512)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4921)\n\tat com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4867)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1320)\n\tat com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1294)\n\tat com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader$$anonfun$getDownloadSize$1.apply(S3ResourceDownloader.scala:164)\n\tat com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader$$anonfun$getDownloadSize$1.apply(S3ResourceDownloader.scala:161)\n\tat scala.Option.flatMap(Option.scala:171)\n\tat com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader.getDownloadSize(S3ResourceDownloader.scala:160)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.getDownloadSize(ResourceDownloader.scala:396)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.getDownloadSize(ResourceDownloader.scala:488)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.getDownloadSize(ResourceDownloader.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UPPJ0m3hmNjt","colab":{}},"source":["nlpPipelineDF = nlpPipeline.fit(pubMedDF).transform(pubMedDF)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LgDdXnn2mNjv"},"source":["### Let's create Spark ML Pipeline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5BDQ5C6hmNjw","colab":{}},"source":["# SPark ML Pipeline\n","\n","cv = CountVectorizer(inputCol=\"finished_chunk\", outputCol=\"features\", vocabSize=1000, minDF=10.0, minTF=10.0)\n","idf = IDF(inputCol=\"features\", outputCol=\"idf\")\n","lda = LDA(k=10, maxIter=5)\n","### Let's create Spark-NLP Pipeline\n","mlPipeline = Pipeline(stages=[\n","    cv,\n","    idf,\n","    lda\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lM6qSQKHmNjy"},"source":["### We are going to train Spark ML Pipeline by using Spark-NLP Pipeline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EXinh1fEmNjz","colab":{}},"source":["# Let's create Spark-NLP Pipeline\n","mlModel = mlPipeline.fit(nlpPipelineDF)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i34QTAtdmNj2","colab":{}},"source":["mlPipelineDF = mlModel.transform(nlpPipelineDF)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aTbgegKhmNj4","colab":{}},"source":["mlPipelineDF.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vf4y90rGmNj7","colab":{}},"source":["ldaModel = mlModel.stages[2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F5oFHh8qmNj9","colab":{}},"source":["ll = ldaModel.logLikelihood(mlPipelineDF)\n","lp = ldaModel.logPerplexity(mlPipelineDF)\n","print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n","print(\"The upper bound on perplexity: \" + str(lp))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lfYw9B1amNj_","colab":{}},"source":["# Describe topics.\n","print(\"The topics described by their top-weighted terms:\")\n","ldaModel.describeTopics(3).show(truncate=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X6w3HawgmNkC"},"source":["### Let's look at out topics\n","NOTE: More cleaning, filtering, playing around with `CountVectorizer`, and more iterations in `LDA` will result in better Topic Modelling results."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5PRurlj8mNkD","colab":{}},"source":["# Output topics. Each is a distribution over words (matching word count vectors)\n","print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n","      + \" words):\")\n","\n","topics = ldaModel.describeTopics(50)\n","topics_rdd = topics.rdd\n","\n","vocab = mlModel.stages[0].vocabulary\n","\n","topics_words = topics_rdd\\\n","       .map(lambda row: row['termIndices'])\\\n","       .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n","       .collect()\n","\n","for idx, topic in enumerate(topics_words):\n","    print(\"topic: \", idx)\n","    print(\"----------\")\n","    for word in topic:\n","       print(word)\n","    print(\"----------\")"],"execution_count":null,"outputs":[]}]}