{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of EnglishTTS.ipynb","provenance":[{"file_id":"https://github.com/tugstugi/pytorch-dc-tts/blob/master/notebooks/EnglishTTS.ipynb","timestamp":1594787853430}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YmNSTzuGFiDj","colab_type":"text"},"source":["# English Text To Speech\n","\n","This is an open source English text to speech implementing the paper:\n","```\n","Hideyuki Tachibana, Katsuya Uenoyama, Shunsuke Aihara\n","Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention\n","https://arxiv.org/abs/1710.08969\n","```\n","\n","The repo containing the implementation can be found here: [https://github.com/tugstugi/pytorch-dc-tts](https://github.com/tugstugi/pytorch-dc-tts). The [LJ-Speech](https://keithito.com/LJ-Speech-Dataset/) is used as the training dataset."]},{"cell_type":"markdown","metadata":{"id":"N4vqXzZI2fro","colab_type":"text"},"source":["## Setup\n","\n","### Install dependencies"]},{"cell_type":"code","metadata":{"id":"G4-CKFr22uBB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595132503390,"user_tz":-330,"elapsed":11250,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"129e12b4-9827-4728-caf6-9b6899a1cd30"},"source":["import os\n","from os.path import exists, join, expanduser\n","\n","project_name = \"pytorch-dc-tts\"\n","if not exists(project_name):\n","  ! git clone --quiet https://github.com/tugstugi/{project_name}\n","  ! cd {project_name} && pip install -q -r requirements.txt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |█                               | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 5.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 7.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 7.5MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n5XKzALS3P1r","colab_type":"text"},"source":["### Download pretrained models"]},{"cell_type":"code","metadata":{"id":"Dc5b0-HV3eh7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595132538444,"user_tz":-330,"elapsed":24474,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["# download text2mel\n","if not exists(\"ljspeech-text2mel.pth\"):\n","  ! wget -q -O ljspeech-text2mel.pth https://www.dropbox.com/s/4t13ugxzzgnocbj/step-300K.pth\n","\n","# download SSRN\n","if not exists(\"ljspeech-ssrn.pth\"):\n","  ! wget -q -O ljspeech-ssrn.pth https://www.dropbox.com/s/gw4aqrgcvccmg0g/step-100K.pth"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TiZA7qgn7kCj","colab_type":"text"},"source":["## Synthesize\n","\n","### Prepare models\n"]},{"cell_type":"code","metadata":{"id":"LjqMQn2y6j58","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595132549122,"user_tz":-330,"elapsed":6696,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["import sys\n","sys.path.append(project_name)\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")  # ignore warnings in this notebook\n","\n","import numpy as np\n","import torch\n","\n","from tqdm import *\n","import IPython\n","from IPython.display import Audio\n","\n","from hparams import HParams as hp\n","from audio import save_to_wav\n","from models import Text2Mel, SSRN\n","from datasets.lj_speech import vocab, idx2char, get_test_data"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"eVxfJD6I7yca","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595132565946,"user_tz":-330,"elapsed":2806,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["torch.set_grad_enabled(False)\n","text2mel = Text2Mel(vocab)\n","text2mel.load_state_dict(torch.load(\"ljspeech-text2mel.pth\").state_dict())\n","text2mel = text2mel.eval()\n","ssrn = SSRN()\n","ssrn.load_state_dict(torch.load(\"ljspeech-ssrn.pth\").state_dict())\n","ssrn = ssrn.eval()"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h_VB9q8q_Wq1","colab_type":"text"},"source":["### Allowed characters\n","\n","abcdefghijklmnopqrstuvwxyz'.?\n","\n","### Sentences to synthesize"]},{"cell_type":"code","metadata":{"id":"GtgxZbfG_DgM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595132638154,"user_tz":-330,"elapsed":1392,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}}},"source":["SENTENCES = [\n","    \"We are doing our NLP class in Learning Bay\",\n","    \"Glue the sheet to the dark blue background.\",\n","    \"It's easy to tell the depth of a well.\",\n","    \"These days a chicken leg is a rare dish.\",\n","    \"Rice is often served in round bowls.\",\n","    \"The juice of lemons makes fine punch.\",\n","    \"The box was thrown beside the parked truck.\",\n","    \"The hogs were fed chopped corn and garbage.\",\n","    \"Four hours of steady work faced us.\",\n","    \"Large size in stockings is hard to sell.\",\n","    \"The boy was there when the sun rose.\",\n","    \"A rod is used to catch pink salmon.\",\n","    \"The source of the huge river is the clear spring.\",\n","    \"Kick the ball straight and follow through.\",\n","    \"Help the woman get back to her feet.\",\n","    \"A pot of tea helps to pass the evening.\",\n","    \"Smoky fires lack flame and heat.\",\n","    \"The soft cushion broke the man's fall.\",\n","    \"The salt breeze came across from the sea.\",\n","    \"The girl at the booth sold fifty bonds.\"\n","]"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yT7GG7OA_0Tp","colab_type":"text"},"source":["### Synthetize on CPU"]},{"cell_type":"code","metadata":{"id":"jLU2p4Gq_12d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1YskBWyH1DbeGxlOu4wj6I_D6waYGFmGV"},"executionInfo":{"status":"ok","timestamp":1595132777441,"user_tz":-330,"elapsed":131993,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"3bc271ec-755d-4d7a-c069-1ed1b230db54"},"source":["# synthetize by one by one because there is a batch processing bug!\n","for i in range(len(SENTENCES)):\n","    sentence = SENTENCES[i]\n","    normalized_sentence = \"\".join([c if c.lower() in vocab else '' for c in sentence])\n","    print(normalized_sentence)\n","    \n","    sentences = [normalized_sentence]\n","    max_N = len(normalized_sentence)\n","    L = torch.from_numpy(get_test_data(sentences, max_N))\n","    zeros = torch.from_numpy(np.zeros((1, hp.n_mels, 1), np.float32))\n","    Y = zeros\n","    A = None\n","\n","    for t in range(hp.max_T):\n","      _, Y_t, A = text2mel(L, Y, monotonic_attention=True)\n","      Y = torch.cat((zeros, Y_t), -1)\n","      _, attention = torch.max(A[0, :, -1], 0)\n","      attention = attention.item()\n","      if L[0, attention] == vocab.index('E'):  # EOS\n","          break\n","\n","    _, Z = ssrn(Y)\n","    \n","    Z = Z.cpu().detach().numpy()\n","    save_to_wav(Z[0, :, :].T, '%d.wav' % (i + 1))\n","    IPython.display.display(Audio('%d.wav' % (i + 1), rate=hp.sr))"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}