{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6- Sarcasm Classifiers (TF-IDF).ipynb","provenance":[]},"kernelspec":{"display_name":"spark_nlp_2.4.4","language":"python","name":"spark_nlp_2.4.4"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XXVsuNfVzAbZ"},"source":["![](https://memesbams.com/wp-content/uploads/2017/11/sheldon-sarcasm-meme.jpg)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kii7lHk_zAba"},"source":["https://www.kaggle.com/danofer/sarcasm\n","<div class=\"markdown-converter__text--rendered\"><h3>Context</h3>\n","\n","<p>This dataset contains 1.3 million Sarcastic comments from the Internet commentary website Reddit. The dataset was generated by scraping comments from Reddit (not by me :)) containing the <code>\\s</code> ( sarcasm) tag. This tag is often used by Redditors to indicate that their comment is in jest and not meant to be taken seriously, and is generally a reliable indicator of sarcastic comment content.</p>\n","\n","<h3>Content</h3>\n","\n","<p>Data has balanced and imbalanced (i.e true distribution) versions. (True ratio is about 1:100). The\n","corpus has 1.3 million sarcastic statements, along with what they responded to as well as many non-sarcastic comments from the same source.</p>\n","\n","<p>Labelled comments are in the <code>train-balanced-sarcasm.csv</code> file.</p>\n","\n","<h3>Acknowledgements</h3>\n","\n","<p>The data was gathered by: Mikhail Khodak and Nikunj Saunshi and Kiran Vodrahalli for their article \"<a href=\"https://arxiv.org/abs/1704.05579\" rel=\"nofollow\">A Large Self-Annotated Corpus for Sarcasm</a>\". The data is hosted <a href=\"http://nlp.cs.princeton.edu/SARC/0.0/\" rel=\"nofollow\">here</a>.</p>\n","\n","<p>Citation:</p>\n","\n","<pre><code>@unpublished{SARC,\n","  authors={Mikhail Khodak and Nikunj Saunshi and Kiran Vodrahalli},\n","  title={A Large Self-Annotated Corpus for Sarcasm},\n","  url={https://arxiv.org/abs/1704.05579},\n","  year=2017\n","}\n","</code></pre>\n","\n","<p><a href=\"http://nlp.cs.princeton.edu/SARC/0.0/readme.txt\" rel=\"nofollow\">Annotation of files in the original dataset: readme.txt</a>.</p>\n","\n","<h3>Inspiration</h3>\n","\n","<ul>\n","<li>Predicting sarcasm and relevant NLP features (e.g. subjective determinant, racism, conditionals, sentiment heavy words, \"Internet Slang\" and specific phrases). </li>\n","<li>Sarcasm vs Sentiment</li>\n","<li>Unusual linguistic features such as caps, italics, or elongated words. e.g., \"Yeahhh, I'm sure THAT is the right answer\".</li>\n","<li>Topics that people tend to react to sarcastically</li>\n","</ul></div>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L2XjUpo4zG-G","colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"status":"ok","timestamp":1595136110870,"user_tz":-330,"elapsed":18214,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"74c4d288-24b4-4d4c-aa1d-bd893983d892"},"source":["import os\n","\n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! java -version\n","\n","# Install pyspark\n","! pip install --ignore-installed pyspark==2.4.4\n","\n","# Install Spark NLP\n","! pip install --ignore-installed spark-nlp==2.5.1"],"execution_count":4,"outputs":[{"output_type":"stream","text":["openjdk version \"1.8.0_252\"\n","OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n","OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n","Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n","Collecting py4j==0.10.7\n","  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.0.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["py4j","pyspark"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting spark-nlp==2.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/b4/db653f8080a446de8ce981b262d85c85c61de7e920930726da0d1c6b4c65/spark_nlp-2.5.1-py2.py3-none-any.whl (121kB)\n","\r\u001b[K     |██▊                             | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 6.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 61kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 5.0MB/s \n","\u001b[?25hInstalling collected packages: spark-nlp\n","Successfully installed spark-nlp-2.5.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["com","sparknlp"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I_Q9S-qHzAbc","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"error","timestamp":1595136172486,"user_tz":-330,"elapsed":3872,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"4e1503b6-9224-48b6-a255-26373f6e81ce"},"source":["import sys\n","import time\n","import sparknlp\n","\n","from pyspark.sql import SparkSession\n","packages = [\n","    'JohnSnowLabs:spark-nlp: 2.4.2'\n","]\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"ML SQL session\") \\\n","    .config('spark.jars.packages', ','.join(packages)) \\\n","    .config('spark.executor.instances','2') \\\n","    .config(\"spark.executor.memory\", \"2g\") \\\n","    .config(\"spark.driver.memory\",\"2g\") \\\n","    .getOrCreate()"],"execution_count":3,"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-63bb5f7da67e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m'JohnSnowLabs:spark-nlp: 2.4.2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m ]\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ML SQL session\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.jars.packages'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.executor.instances'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.executor.memory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2g\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.driver.memory\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2g\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mJVM\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_launch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36m_launch_gateway\u001b[0;34m(conf, insecure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Xi0xUcsDzAbg","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"error","timestamp":1595136139718,"user_tz":-330,"elapsed":1510,"user":{"displayName":"arghya mukherjee","photoUrl":"","userId":"18197738747789081595"}},"outputId":"b7fd2e3c-dd97-4f2e-9c36-fd3d08e1e878"},"source":["print(\"Spark NLP version: \", sparknlp.version())\n","print(\"Apache Spark version: \", spark.version)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Spark NLP version:  2.5.1\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-444da6cf3ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Spark NLP version: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparknlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Apache Spark version: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DDnbYfBXzAbk","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":66628,"status":"ok","timestamp":1569001938804,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"691007be-7a20-4739-8fb3-7b08a4e5bc39"},"source":["! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv -P /tmp"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-02-11 19:18:09--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv\n","Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.237.229\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.237.229|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 255268960 (243M) [text/csv]\n","Saving to: ‘/tmp/train-balanced-sarcasm.csv’\n","\n","train-balanced-sarc 100%[===================>] 243,44M  5,01MB/s    in 33s     \n","\n","2020-02-11 19:18:43 (7,46 MB/s) - ‘/tmp/train-balanced-sarcasm.csv’ saved [255268960/255268960]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"STau1pkazAbn","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":81293,"status":"ok","timestamp":1569001954718,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"e8144476-2fec-42c7-b8ef-4b9e477b5766"},"source":["from pyspark.sql import SQLContext\n","\n","sql = SQLContext(spark)\n","\n","trainBalancedSarcasmDF = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/tmp/train-balanced-sarcasm.csv\")\n","trainBalancedSarcasmDF.printSchema()\n","\n","# Let's create a temp view (table) for our SQL queries\n","trainBalancedSarcasmDF.createOrReplaceTempView('data')\n","\n","sql.sql('SELECT COUNT(*) FROM data').collect()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["root\n"," |-- label: integer (nullable = true)\n"," |-- comment: string (nullable = true)\n"," |-- author: string (nullable = true)\n"," |-- subreddit: string (nullable = true)\n"," |-- score: string (nullable = true)\n"," |-- ups: string (nullable = true)\n"," |-- downs: string (nullable = true)\n"," |-- date: string (nullable = true)\n"," |-- created_utc: string (nullable = true)\n"," |-- parent_comment: string (nullable = true)\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[Row(count(1)=1010826)]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yqLaXP1MzAbq","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"elapsed":86519,"status":"ok","timestamp":1569001960660,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"93a8472b-f7ae-4e69-b141-76e392f65125"},"source":["sql.sql('select * from data limit 20').show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+--------------------+------------------+------------------+-----+---+-----+-------+-------------------+--------------------+\n","|label|             comment|            author|         subreddit|score|ups|downs|   date|        created_utc|      parent_comment|\n","+-----+--------------------+------------------+------------------+-----+---+-----+-------+-------------------+--------------------+\n","|    0|          NC and NH.|         Trumpbart|          politics|    2| -1|   -1|2016-10|2016-10-16 23:55:23|Yeah, I get that ...|\n","|    0|You do know west ...|         Shbshb906|               nba|   -4| -1|   -1|2016-11|2016-11-01 00:24:10|The blazers and M...|\n","|    0|They were underdo...|          Creepeth|               nfl|    3|  3|    0|2016-09|2016-09-22 21:45:37|They're favored t...|\n","|    0|\"This meme isn't ...|         icebrotha|BlackPeopleTwitter|   -8| -1|   -1|2016-10|2016-10-18 21:03:47|deadass don't kil...|\n","|    0|I could use one o...|         cush2push|MaddenUltimateTeam|    6| -1|   -1|2016-12|2016-12-30 17:00:13|Yep can confirm I...|\n","|    0|I don't pay atten...|       only7inches|         AskReddit|    0|  0|    0|2016-09|2016-09-02 10:35:08|do you find arian...|\n","|    0|Trick or treating...|       only7inches|         AskReddit|    1| -1|   -1|2016-10|2016-10-23 21:43:03|What's your weird...|\n","|    0|Blade Mastery+Mas...|         P0k3rm4s7|     FFBraveExvius|    2| -1|   -1|2016-10|2016-10-13 21:13:55|Probably Sephirot...|\n","|    0|You don't have to...|        SoupToPots|      pcmasterrace|    1| -1|   -1|2016-10|2016-10-27 19:11:06|What to upgrade? ...|\n","|    0|I would love to s...|          chihawks|      Lollapalooza|    2| -1|   -1|2016-11|2016-11-21 23:39:12|Probably count Ka...|\n","|    0|I think a signifi...|ThisIsNotKimJongUn|          politics|   92| 92|    0|2016-09|2016-09-20 17:53:52|I bet if that mon...|\n","|    0|Damn I was hoping...|        Kvetch__22|          baseball|   14| -1|   -1|2016-10|2016-10-28 09:07:50|James Shields Wil...|\n","|    0|They have an agenda.|        Readbooks6|          exmormon|    4| -1|   -1|2016-10|2016-10-15 01:14:03|There's no time t...|\n","|    0|         Great idea!|        pieman2005|   fantasyfootball|    1| -1|   -1|2016-10|2016-10-06 23:27:53|Team Specific Thr...|\n","|    0|Ayy bb wassup, it...|      Jakethejoker|          NYGiants|   29| 29|    0|2016-09|2016-09-19 18:46:58|Ill give you a hi...|\n","|    0|       what the fuck|            Pishwi|         AskReddit|   22| -1|   -1|2016-11|2016-11-04 20:10:33|Star Wars, easy. ...|\n","|    0|              noted.|         kozmo1313|        NewOrleans|    2| -1|   -1|2016-12|2016-12-20 21:59:45|    You're adorable.|\n","|    0|because it's what...|         kozmo1313|          politics|   15| -1|   -1|2016-12|2016-12-26 20:10:45|He actually acts ...|\n","|    0|why you fail me, ...|         kozmo1313|  HillaryForPrison|    1|  1|    0|2016-09|2016-09-18 13:02:45|Clinton struggles...|\n","|    0|Pre-Flashpoint Cl...|   BreakingGarrick|          superman|    2|  2|    0|2016-09|2016-09-16 02:34:04|Is that the Older...|\n","+-----+--------------------+------------------+------------------+-----+---+-----+-------+-------------------+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5E4g57_vzAbs","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"elapsed":91469,"status":"ok","timestamp":1569001966381,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"281e22d5-478c-46c3-b01c-4009b610664e"},"source":["sql.sql('select label,count(*) as cnt from data group by label order by cnt desc').show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+------+\n","|label|   cnt|\n","+-----+------+\n","|    0|505413|\n","|    1|505413|\n","+-----+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AXI3FgNpzAbv","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":94496,"status":"ok","timestamp":1569001970177,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"edb71b3f-0eae-4bed-9452-dcfe3d860cdf"},"source":["sql.sql('select count(*) from data where comment is null').collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(count(1)=53)]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q-lStZ4FzAby","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"elapsed":98233,"status":"ok","timestamp":1569001974682,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"9640479d-df79-4076-b54c-e127cdc55efc"},"source":["df = sql.sql('select label,concat(parent_comment,\"\\n\",comment) as comment from data where comment is not null and parent_comment is not null limit 100000')\n","print(type(df))\n","df.printSchema()\n","df.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pyspark.sql.dataframe.DataFrame'>\n","root\n"," |-- label: integer (nullable = true)\n"," |-- comment: string (nullable = true)\n","\n","+-----+--------------------+\n","|label|             comment|\n","+-----+--------------------+\n","|    0|Yeah, I get that ...|\n","|    0|The blazers and M...|\n","|    0|They're favored t...|\n","|    0|deadass don't kil...|\n","|    0|Yep can confirm I...|\n","|    0|do you find arian...|\n","|    0|What's your weird...|\n","|    0|Probably Sephirot...|\n","|    0|What to upgrade? ...|\n","|    0|Probably count Ka...|\n","|    0|I bet if that mon...|\n","|    0|James Shields Wil...|\n","|    0|There's no time t...|\n","|    0|Team Specific Thr...|\n","|    0|Ill give you a hi...|\n","|    0|Star Wars, easy. ...|\n","|    0|You're adorable.\n","...|\n","|    0|He actually acts ...|\n","|    0|Clinton struggles...|\n","|    0|Is that the Older...|\n","+-----+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jT-8qiuzzAb0","colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":223854,"status":"ok","timestamp":1569002101544,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"d916728e-dccb-472b-c549-a1b9095b51b6"},"source":["from sparknlp.annotator import *\n","from sparknlp.common import *\n","from sparknlp.base import *\n","\n","from pyspark.ml import Pipeline\n","\n","\n","document_assembler = DocumentAssembler() \\\n","    .setInputCol(\"comment\") \\\n","    .setOutputCol(\"document\")\n","    \n","sentence_detector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\") \\\n","    .setUseAbbreviations(True)\n","    \n","tokenizer = Tokenizer() \\\n","  .setInputCols([\"sentence\"]) \\\n","  .setOutputCol(\"token\")\n","\n","stemmer = Stemmer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"stem\")\n","    \n","normalizer = Normalizer() \\\n","    .setInputCols([\"stem\"]) \\\n","    .setOutputCol(\"normalized\")\n","\n","finisher = Finisher() \\\n","    .setInputCols([\"normalized\"]) \\\n","    .setOutputCols([\"ntokens\"]) \\\n","    .setOutputAsArray(True) \\\n","    .setCleanAnnotations(True)\n","\n","nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, stemmer, normalizer, finisher])\n","nlp_model = nlp_pipeline.fit(df)\n","processed = nlp_model.transform(df).persist()\n","processed.count()\n","processed.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+--------------------+--------------------+\n","|label|             comment|             ntokens|\n","+-----+--------------------+--------------------+\n","|    0|Yeah, I get that ...|[yeah, i, get, th...|\n","|    0|The blazers and M...|[the, blazer, and...|\n","|    0|They're favored t...|[theyr, favor, to...|\n","|    0|deadass don't kil...|[deadass, dont, k...|\n","|    0|Yep can confirm I...|[yep, can, confir...|\n","|    0|do you find arian...|[do, you, find, a...|\n","|    0|What's your weird...|[what, your, weir...|\n","|    0|Probably Sephirot...|[probabl, sephiro...|\n","|    0|What to upgrade? ...|[what, to, upgrad...|\n","|    0|Probably count Ka...|[probabl, count, ...|\n","|    0|I bet if that mon...|[i, bet, if, that...|\n","|    0|James Shields Wil...|[jame, shield, wi...|\n","|    0|There's no time t...|[there, no, time,...|\n","|    0|Team Specific Thr...|[team, specif, th...|\n","|    0|Ill give you a hi...|[ill, give, you, ...|\n","|    0|Star Wars, easy. ...|[star, war, easi,...|\n","|    0|You're adorable.\n","...|  [your, ador, note]|\n","|    0|He actually acts ...|[he, actual, act,...|\n","|    0|Clinton struggles...|[clinton, struggl...|\n","|    0|Is that the Older...|[i, that, the, ol...|\n","+-----+--------------------+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sudqXsAWzAb3","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":224328,"status":"ok","timestamp":1569002103231,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"74130370-d420-4312-ca3e-5389d16e35c6"},"source":["train, test = processed.randomSplit(weights=[0.7, 0.3], seed=123)\n","print(train.count())\n","print(test.count())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["70136\n","29864\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zUG7bWk7zAb5","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"elapsed":237797,"status":"ok","timestamp":1569002117605,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"5ae0c774-5ca4-49c6-97ed-a0d2deb3855b"},"source":["from pyspark.ml import feature as spark_ft\n","\n","stopWords = spark_ft.StopWordsRemover.loadDefaultStopWords('english')\n","sw_remover = spark_ft.StopWordsRemover(inputCol='ntokens', outputCol='clean_tokens', stopWords=stopWords)\n","tf = spark_ft.CountVectorizer(vocabSize=500, inputCol='clean_tokens', outputCol='tf')\n","idf = spark_ft.IDF(minDocFreq=5, inputCol='tf', outputCol='idf')\n","\n","feature_pipeline = Pipeline(stages=[sw_remover, tf, idf])\n","feature_model = feature_pipeline.fit(train)\n","\n","train_featurized = feature_model.transform(train).persist()\n","train_featurized.count()\n","train_featurized.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|label|             comment|             ntokens|        clean_tokens|                  tf|                 idf|\n","+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|    0|              !\n","Goes|               [goe]|               [goe]|   (500,[375],[1.0])|(500,[375],[4.866...|\n","|    0|!completed\n","!compl...|  [complet, complet]|  [complet, complet]|   (500,[227],[2.0])|(500,[227],[8.875...|\n","|    0|\"\"\" \"\"Very Right ...|[veri, right, win...|[veri, right, win...|(500,[1,7,31,77,9...|(500,[1,7,31,77,9...|\n","|    0|\"\"\" Perhaps you n...|[perhap, you, ne,...|[perhap, ne, stro...|    (500,[34],[1.0])|(500,[34],[3.1336...|\n","|    0|\"\"\" This covering...|[thi, cover, not,...|[thi, cover, onli...|(500,[0,6,14,18,2...|(500,[0,6,14,18,2...|\n","|    0|\"\"\"*Kirk\n","I am sin...|[kirk, i, am, sin...|[kirk, singl, gue...|(500,[31,168,348]...|(500,[31,168,348]...|\n","|    0|\"\"\"*looks at hand...|[look, at, hand, ...|[look, hand, doe,...|(500,[22,58,211,2...|(500,[22,58,211,2...|\n","|    0|\"\"\"+100\"\" indicat...|[+, indic, come, ...|[+, indic, come, ...|(500,[5,9,18,57,9...|(500,[5,9,18,57,9...|\n","|    0|\"\"\".$witty_remark...|[wittyremark, shi...|[wittyremark, shi...|         (500,[],[])|         (500,[],[])|\n","|    0|\"\"\"... and Fancy ...|[and, fanci, feas...|[fanci, feast, so...|     (500,[1],[1.0])|(500,[1],[1.87740...|\n","|    0|\"\"\"...and then th...|[and, then, the, ...|[entir, food, cou...|(500,[14,31,64,19...|(500,[14,31,64,19...|\n","|    0|\"\"\"...newtons.\"\" ...|[newton, which, i...|[newton, dont, ge...|(500,[0,5,6,208],...|(500,[0,5,6,208],...|\n","|    0|\"\"\"100 level and ...|[level, and, k, e...|[level, k, easfc,...|(500,[0,1,27,56,8...|(500,[0,1,27,56,8...|\n","|    0|\"\"\"8 operators.\"\"...|[oper, well, i, m...|[oper, well, mean...|(500,[5,24,51,66,...|(500,[5,24,51,66,...|\n","|    0|\"\"\"@wikileaks - A...|[wikileak, americ...|[wikileak, americ...|   (500,[300],[1.0])|(500,[300],[4.703...|\n","|    0|\"\"\"A Cyborg... Ni...|[a, cyborg, ninja...|[cyborg, ninja, n...|         (500,[],[])|         (500,[],[])|\n","|    0|\"\"\"A Victoria's S...|[a, victoria, sec...|[victoria, secret...|(500,[2,139,173,2...|(500,[2,139,173,2...|\n","|    0|\"\"\"A basic aspect...|[a, basic, aspect...|[basic, aspect, f...|(500,[0,1,2,3,10,...|(500,[0,1,2,3,10,...|\n","|    0|\"\"\"A sense of pur...|[a, sens, of, pur...|[sens, purpos, sh...|(500,[131,133,326...|(500,[131,133,326...|\n","|    0|\"\"\"Agreed. I thin...|[agr, i, think, w...|[agr, think, issu...|(500,[0,1,7,9,29,...|(500,[0,1,7,9,29,...|\n","+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"azBXX9RdzAb8","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"elapsed":237148,"status":"ok","timestamp":1569002118068,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"4ba23558-ddb5-42bd-e32a-89b449c2a829"},"source":["train_featurized.groupBy(\"label\").count().show()\n","train_featurized.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+-----+\n","|label|count|\n","+-----+-----+\n","|    0|40466|\n","|    1|29670|\n","+-----+-----+\n","\n","root\n"," |-- label: integer (nullable = true)\n"," |-- comment: string (nullable = true)\n"," |-- ntokens: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- clean_tokens: array (nullable = true)\n"," |    |-- element: string (containsNull = true)\n"," |-- tf: vector (nullable = true)\n"," |-- idf: vector (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aN1hz2zOzAcB","colab":{}},"source":["from pyspark.ml import classification as spark_cls\n","\n","rf = spark_cls. RandomForestClassifier(labelCol=\"label\", featuresCol=\"idf\", numTrees=100)\n","\n","model = rf.fit(train_featurized)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QhsSesndzAcE","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"elapsed":251748,"status":"ok","timestamp":1569002135194,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"76739578-c02d-468d-edeb-2d4e8dd1294d"},"source":["test_featurized = feature_model.transform(test)\n","preds = model.transform(test_featurized)\n","preds.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n","|label|             comment|             ntokens|        clean_tokens|                  tf|                 idf|       rawPrediction|         probability|prediction|\n","+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n","|    0|!RemindMe 1 week\n","...|[remindm, week, r...|[remindm, week, r...|(500,[56,132],[1....|(500,[56,132],[3....|[58.8715006890861...|[0.58871500689086...|       0.0|\n","|    0|!Remindme 2 weeks...|[remindm, week, r...|[remindm, week, r...|   (500,[132],[2.0])|(500,[132],[8.254...|[58.8715006890861...|[0.58871500689086...|       0.0|\n","|    0|!SH!TPOST!: All t...|[shtpost, all, th...|[shtpost, poor, u...|(500,[286,476],[1...|(500,[286,476],[4...|[58.6927668196978...|[0.58692766819697...|       0.0|\n","|    0|\"\"\"**FUCK** Cloud...|[fuck, cloud, lin...|[fuck, cloud, lin...|(500,[30,35],[1.0...|(500,[30,35],[3.0...|[58.8715006890861...|[0.58871500689086...|       0.0|\n","|    0|\"\"\"*Komrad\n","\"*\"\"Th...|[komrad, those, w...|[komrad, prousa, ...|   (500,[308],[1.0])|(500,[308],[4.833...|[57.9747819444301...|[0.57974781944430...|       0.0|\n","|    0|\"\"\"... thanks to ...|[thank, to, a, pa...|[thank, parad, tr...|(500,[18,31,81,14...|(500,[18,31,81,14...|[57.8971892730668...|[0.57897189273066...|       0.0|\n","|    0|\"\"\"...FUCK IS THA...|[fuck, i, tha, de...|[fuck, tha, death...|(500,[3,11,29,30,...|(500,[3,11,29,30,...|[58.8662918135306...|[0.58866291813530...|       0.0|\n","|    0|\"\"\"...I'm Going T...|[im, go, to, end,...|[im, go, end, dre...|(500,[8,11,119],[...|(500,[8,11,119],[...|[59.1473600893163...|[0.59147360089316...|       0.0|\n","|    0|\"\"\"A SMALL FUCKIN...|[a, small, fuck, ...|[small, fuck, hol...|(500,[30,31,57,42...|(500,[30,31,57,42...|[57.9152715153977...|[0.57915271515397...|       0.0|\n","|    0|\"\"\"A new brick wa...|[a, new, brick, w...|[new, brick, wall...|(500,[3,32,43,124...|(500,[3,32,43,124...|[58.7612174551342...|[0.58761217455134...|       0.0|\n","|    0|\"\"\"Add dabbing to...|[add, dab, to, mi...|[add, dab, minecr...|   (500,[358],[1.0])|(500,[358],[4.866...|[58.8715006890861...|[0.58871500689086...|       0.0|\n","|    0|\"\"\"All according ...|[all, accord, to,...|[accord, keikaku,...|(500,[51,350],[1....|(500,[51,350],[3....|[58.8715006890861...|[0.58871500689086...|       0.0|\n","|    0|\"\"\"An unmet playe...|[an, unmet, playe...|[unmet, player, h...|(500,[0,1,7,8,14,...|(500,[0,1,7,8,14,...|[58.3304632923714...|[0.58330463292371...|       0.0|\n","|    0|\"\"\"And bacon. Lot...|[and, bacon, lot,...|[bacon, lot, lot,...|(500,[6,74,82,483...|(500,[6,74,82,483...|[58.9443340184272...|[0.58944334018427...|       0.0|\n","|    0|\"\"\"And later... S...|[and, later, some...|[later, someth, f...|(500,[54,73,120,1...|(500,[54,73,120,1...|[58.9578427385407...|[0.58957842738540...|       0.0|\n","|    0|\"\"\"And please tel...|[and, pleas, tell...|[pleas, tell, mom...|(500,[0,43,94,116...|(500,[0,43,94,116...|[58.8715006890861...|[0.58871500689086...|       0.0|\n","|    0|\"\"\"Angry Birds?\"\"...|[angri, bird, u, ...|[angri, bird, u, ...|(500,[12,43,44,28...|(500,[12,43,44,28...|[58.8715006890861...|[0.58871500689086...|       0.0|\n","|    0|\"\"\"Any objections...|[ani, object, fuc...|[ani, object, fuc...|(500,[1,30,33,34,...|(500,[1,30,33,34,...|[58.6845929081117...|[0.58684592908111...|       0.0|\n","|    0|\"\"\"Anyway here's ...|[anywai, here, st...|[anywai, stairwai...|   (500,[361],[1.0])|(500,[361],[4.817...|[58.8715006890861...|[0.58871500689086...|       0.0|\n","|    0|\"\"\"Aren't you a C...|[arent, you, a, c...|[arent, christian...|(500,[123,207],[1...|(500,[123,207],[3...|[59.0632707665339...|[0.59063270766533...|       0.0|\n","+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RqIr-E_3zAcG","colab":{}},"source":["pred_df = preds.select('comment', 'label', 'prediction').toPandas()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ly6yCNIqzAcJ","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":253070,"status":"ok","timestamp":1569002138943,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"f4f5e6d6-9610-4d33-aebf-77c2da8346e4"},"source":["pred_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>label</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>!RemindMe 1 week\\n!RemindMe 2 days</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>!Remindme 2 weeks\\n!Remindme 2 weeks</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>!SH!TPOST!: All those poor USA Streamers\\nNow ...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"\"\"**FUCK** Cloud\"\" - Link main\"\\nYep, that's ...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\"\"\"*Komrad\\n\"*\"\"Those were just pro-USA rebels...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             comment  label  prediction\n","0                 !RemindMe 1 week\\n!RemindMe 2 days      0         0.0\n","1               !Remindme 2 weeks\\n!Remindme 2 weeks      0         0.0\n","2  !SH!TPOST!: All those poor USA Streamers\\nNow ...      0         0.0\n","3  \"\"\"**FUCK** Cloud\"\" - Link main\"\\nYep, that's ...      0         0.0\n","4  \"\"\"*Komrad\\n\"*\"\"Those were just pro-USA rebels...      0         0.0"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o-4uxAh5zAcL","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"elapsed":252965,"status":"ok","timestamp":1569002139681,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"8e13d453-dbbe-49ee-e165-766fc6c5e83c"},"source":["import pandas as pd\n","from sklearn import metrics as skmetrics\n","pd.DataFrame(\n","    data=skmetrics.confusion_matrix(pred_df['label'], pred_df['prediction']),\n","    columns=['pred ' + l for l in ['0','1']],\n","    index=['true ' + l for l in ['0','1']]\n",")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pred 0</th>\n","      <th>pred 1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>true 0</th>\n","      <td>17122</td>\n","      <td>102</td>\n","    </tr>\n","    <tr>\n","      <th>true 1</th>\n","      <td>12143</td>\n","      <td>497</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        pred 0  pred 1\n","true 0   17122     102\n","true 1   12143     497"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_F0YX8QgzAcO","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"elapsed":252025,"status":"ok","timestamp":1569002139684,"user":{"displayName":"Alexander Thomas","photoUrl":"","userId":"11939695612384769217"},"user_tz":420},"outputId":"77f24e7d-ccc1-4ac9-f7e5-3d955977a909"},"source":["print(skmetrics.classification_report(pred_df['label'], pred_df['prediction'], \n","                                      target_names=['0','1']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.59      0.99      0.74     17224\n","           1       0.83      0.04      0.08     12640\n","\n","    accuracy                           0.59     29864\n","   macro avg       0.71      0.52      0.41     29864\n","weighted avg       0.69      0.59      0.46     29864\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1fqpil89zAcQ","colab":{}},"source":["spark.stop()"],"execution_count":null,"outputs":[]}]}